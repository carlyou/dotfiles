[project]
name = "cuda"
version = "0.1.0"
requires-python = ">=3.13,<3.14"
dependencies = [
    "setuptools-scm>=9.2.2",
    "torch==2.9.1",
    "torchaudio>=2.9.1",
    "torchvision==0.24.1",
    "vllm",
    # vLLM dependencies (manually added to prevent removal during sync)
    "ray>=2.48",
    "xgrammar>=0.1",
    "flashinfer-python",
    "outlines-core",
    "huggingface>=0.0.1",
    "ipykernel>=7.1.0",
    "transformers[sentencepiece]>=4.57.3",
    "datasets>=4.4.2",
    "evaluate>=0.4.6",
    "accelerate>=1.12.0",
    "scikit-learn>=1.8.0",
    "ipywidgets>=8.1.8",
    "wandb>=0.23.1",
    "numpy>=2.2.6",
    "nbformat>=5.10.4",
    "ninja>=1.13.0",
    "flash-attn>=2.8.3",
    "zstandard>=0.25.0",
    "faiss-cpu>=1.13.2",
]

[[tool.uv.index]]
name = "pytorch-cu130"
url = "https://download.pytorch.org/whl/cu130"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu130", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchvision = [
  { index = "pytorch-cu130", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchaudio = [
  { index = "pytorch-cu130", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
vllm = { git = "https://github.com/vllm-project/vllm.git", rev = "357d435c5" }

[tool.uv]
environments = [
    "sys_platform == 'linux' and platform_machine == 'aarch64'",
]

[tool.uv.extra-build-dependencies]
flash-attn = ["torch"]
